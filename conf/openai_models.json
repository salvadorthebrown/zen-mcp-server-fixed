{
  "_README": {
    "description": "Model metadata for native OpenAI API access - REAL MODELS (January 2025)",
    "documentation": "https://platform.openai.com/docs/models",
    "usage": "Models listed here are exposed directly through the OpenAI provider. Aliases are case-insensitive.",
    "last_updated": "2025-01-11"
  },
  "models": [
    {
      "model_name": "gpt-4o",
      "friendly_name": "OpenAI (GPT-4o)",
      "aliases": ["gpt4o", "4o"],
      "intelligence_score": 18,
      "description": "GPT-4o (128K context, 16K output) - Most advanced multimodal model, faster and cheaper than GPT-4 Turbo",
      "context_window": 128000,
      "max_output_tokens": 16384,
      "supports_extended_thinking": false,
      "supports_system_prompts": true,
      "supports_streaming": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_images": true,
      "supports_temperature": true,
      "max_image_size_mb": 20.0,
      "allow_code_generation": true
    },
    {
      "model_name": "gpt-4o-mini",
      "friendly_name": "OpenAI (GPT-4o-mini)",
      "aliases": ["gpt4o-mini", "4o-mini", "mini"],
      "intelligence_score": 15,
      "description": "GPT-4o-mini (128K context, 16K output) - Faster, cheaper variant of GPT-4o",
      "context_window": 128000,
      "max_output_tokens": 16384,
      "supports_extended_thinking": false,
      "supports_system_prompts": true,
      "supports_streaming": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_images": true,
      "supports_temperature": true,
      "max_image_size_mb": 20.0
    },
    {
      "model_name": "gpt-4-turbo",
      "friendly_name": "OpenAI (GPT-4 Turbo)",
      "aliases": ["gpt4-turbo", "4-turbo", "turbo"],
      "intelligence_score": 17,
      "description": "GPT-4 Turbo (128K context, 4K output) - Previous generation flagship model",
      "context_window": 128000,
      "max_output_tokens": 4096,
      "supports_extended_thinking": false,
      "supports_system_prompts": true,
      "supports_streaming": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_images": true,
      "supports_temperature": true,
      "max_image_size_mb": 20.0
    },
    {
      "model_name": "gpt-4",
      "friendly_name": "OpenAI (GPT-4)",
      "aliases": ["gpt4", "4"],
      "intelligence_score": 16,
      "description": "GPT-4 (8K context, 4K output) - Original GPT-4 model",
      "context_window": 8192,
      "max_output_tokens": 4096,
      "supports_extended_thinking": false,
      "supports_system_prompts": true,
      "supports_streaming": true,
      "supports_function_calling": true,
      "supports_json_mode": false,
      "supports_images": false,
      "supports_temperature": true
    },
    {
      "model_name": "gpt-3.5-turbo",
      "friendly_name": "OpenAI (GPT-3.5 Turbo)",
      "aliases": ["gpt35-turbo", "3.5-turbo", "35-turbo", "gpt35", "3.5"],
      "intelligence_score": 12,
      "description": "GPT-3.5 Turbo (16K context, 4K output) - Fast, cheap legacy model",
      "context_window": 16384,
      "max_output_tokens": 4096,
      "supports_extended_thinking": false,
      "supports_system_prompts": true,
      "supports_streaming": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_images": false,
      "supports_temperature": true
    },
    {
      "model_name": "o1",
      "friendly_name": "OpenAI (O1)",
      "aliases": ["o-1"],
      "intelligence_score": 19,
      "description": "O1 (200K context, 100K output) - Advanced reasoning model for complex problem solving",
      "context_window": 200000,
      "max_output_tokens": 100000,
      "supports_extended_thinking": true,
      "supports_system_prompts": false,
      "supports_streaming": false,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_images": true,
      "supports_temperature": false,
      "max_image_size_mb": 20.0,
      "temperature_constraint": "fixed"
    },
    {
      "model_name": "o1-mini",
      "friendly_name": "OpenAI (O1-mini)",
      "aliases": ["o1mini", "o-1-mini"],
      "intelligence_score": 16,
      "description": "O1-mini (128K context, 65K output) - Faster reasoning model for moderate complexity",
      "context_window": 128000,
      "max_output_tokens": 65536,
      "supports_extended_thinking": true,
      "supports_system_prompts": false,
      "supports_streaming": false,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_images": true,
      "supports_temperature": false,
      "max_image_size_mb": 20.0,
      "temperature_constraint": "fixed"
    },
    {
      "model_name": "o3-mini",
      "friendly_name": "OpenAI (O3-mini)",
      "aliases": ["o3mini", "o-3-mini"],
      "intelligence_score": 17,
      "description": "O3-mini (200K context, 100K output) - Latest reasoning model (released Jan 2025)",
      "context_window": 200000,
      "max_output_tokens": 100000,
      "supports_extended_thinking": true,
      "supports_system_prompts": false,
      "supports_streaming": false,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_images": true,
      "supports_temperature": false,
      "max_image_size_mb": 20.0,
      "temperature_constraint": "fixed"
    }
  ]
}
